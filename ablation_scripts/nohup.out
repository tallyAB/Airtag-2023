Traceback (most recent call last):
  File "create_ablation_sets.py", line 71, in <module>
    gt_indices = np.load('/root/Airtag/ground_truth/S'+str(j+1)+'_number_.npy')
  File "/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py", line 384, in load
    fid = open(file, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/root/Airtag/ground_truth/S1_number_.npy'
python: can't open file '../create_vocab.py': [Errno 2] No such file or directory
python: can't open file '../create_vocab.py': [Errno 2] No such file or directory
python: can't open file '../create_vocab.py': [Errno 2] No such file or directory
python: can't open file '../create_vocab.py': [Errno 2] No such file or directory
mv: cannot stat '/root/AirTag/training_data/AblationOne/vocab_training_preprocessed_logs_S1-CVE-2015-5122_windows': No such file or directory
mv: mv: cannot stat '/root/AirTag/training_data/AblationOne/vocab_training_preprocessed_logs_S3-CVE-2017-11882_windows'cannot stat '/root/AirTag/training_data/AblationOne/vocab_training_preprocessed_logs_S2-CVE-2015-3105_windows': No such file or directory: No such file or directory

mv: cannot stat '/root/AirTag/training_data/AblationOne/vocab_training_preprocessed_logs_S4-CVE-2017-0199_windows_py': No such file or directory
Traceback (most recent call last):
  File "../create_pretraining_data.py", line 469, in <module>
    tf.app.run()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "../create_pretraining_data.py", line 440, in main
    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)
  File "/root/AirTag/tokenization.py", line 165, in __init__
    self.vocab = load_vocab(vocab_file)
  File "/root/AirTag/tokenization.py", line 127, in load_vocab
    token = convert_to_unicode(reader.readline())
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 183, in readline
    self._preread_check()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 85, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 526, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ../training_data/AblationOne/vocab_atlas_single1_ablation_one.txt; No such file or directory
Traceback (most recent call last):
  File "../create_pretraining_data.py", line 469, in <module>
    tf.app.run()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "../create_pretraining_data.py", line 440, in main
    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)
  File "/root/AirTag/tokenization.py", line 165, in __init__
    self.vocab = load_vocab(vocab_file)
  File "/root/AirTag/tokenization.py", line 127, in load_vocab
    token = convert_to_unicode(reader.readline())
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 183, in readline
    self._preread_check()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 85, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 526, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ../training_data/AblationOne/vocab_atlas_single3_ablation_one.txt; No such file or directory
Traceback (most recent call last):
  File "../create_pretraining_data.py", line 469, in <module>
    tf.app.run()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "../create_pretraining_data.py", line 440, in main
    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)
  File "/root/AirTag/tokenization.py", line 165, in __init__
    self.vocab = load_vocab(vocab_file)
  File "/root/AirTag/tokenization.py", line 127, in load_vocab
    token = convert_to_unicode(reader.readline())
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 183, in readline
    self._preread_check()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 85, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 526, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ../training_data/AblationOne/vocab_atlas_single4_ablation_one.txt; No such file or directory
Traceback (most recent call last):
  File "../create_pretraining_data.py", line 469, in <module>
    tf.app.run()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "../create_pretraining_data.py", line 440, in main
    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)
  File "/root/AirTag/tokenization.py", line 165, in __init__
    self.vocab = load_vocab(vocab_file)
  File "/root/AirTag/tokenization.py", line 127, in load_vocab
    token = convert_to_unicode(reader.readline())
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 183, in readline
    self._preread_check()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py", line 85, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 526, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ../training_data/AblationOne/vocab_atlas_single2_ablation_one.txt; No such file or directory
